{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8rPeWni5snYnOKzluP28B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albim72/ML_ZAAWANSOWANY_11/blob/main/autoenkoder_wariacyjny_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr3wqzViYeGN",
        "outputId": "a62601c1-45df-4e07-9183-a4ab8d1168c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.23.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.1.8)\n",
            "Requirement already satisfied: typing-extensions<4.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-probability"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzUfK6AZaH0I",
        "outputId": "e061a6dd-9d46-4d51-94a1-01e1a01db4fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.23.5)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghA2PqzWaQMH",
        "outputId": "f6636f37-5db1-47f8-90a2-2d8f9b5c7924"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-4p1x9l73\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-4p1x9l73\n",
            "  Resolved https://github.com/tensorflow/docs to commit af33301a434ea70e104865b9d2e93e230494c1cb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor (from tensorflow-docs==2023.10.27.81990)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (3.1.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (5.9.2)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2023.10.27.81990) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==2023.10.27.81990) (2.1.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.10.27.81990) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.10.27.81990) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.10.27.81990) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2023.10.27.81990) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.10.27.81990) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.10.27.81990) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.10.27.81990) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.10.27.81990) (0.13.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow-docs==2023.10.27.81990) (4.0.0)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-2023.10.27.81990-py3-none-any.whl size=184142 sha256=44240a88b6b1dc3139093c964008724293dc2fe24f022ac0c0080ab1aa4aac4d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hv4biypi/wheels/86/0f/1e/3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: astor, tensorflow-docs\n",
            "Successfully installed astor-0.8.1 tensorflow-docs-2023.10.27.81990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import time"
      ],
      "metadata": {
        "id": "NQzu430gayMK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ładowanie zbioru danych\n",
        "(train_images, _),(test_images, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-ScVwoobmXR",
        "outputId": "00d48ed7-6093-4977-aefd-93582cd29679"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(images):\n",
        "  images = images.reshape((images.shape[0],28,28,1))/255.\n",
        "  return np.where(images>.5,1.0,0.0).astype('float32')\n",
        "\n",
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)"
      ],
      "metadata": {
        "id": "_Fm7TiMCb64L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 60000\n",
        "batch_size = 32\n",
        "test_size = 10000"
      ],
      "metadata": {
        "id": "-zeBlIKPcmc2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#użyjemy tf.data do grupowania i tasowania danych\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices(train_images).shuffle(train_size).batch(batch_size))\n",
        "test_dataset = (tf.data.Dataset.from_tensor_slices(test_images).shuffle(test_size).batch(batch_size))"
      ],
      "metadata": {
        "id": "GGjvI_0ccwF9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Architektura sieci\n",
        "class CVAE(tf.keras.Model):\n",
        "  \"\"\"Konwolucyjny enkoder wariacyjny\"\"\"\n",
        "  def __init__(self,latent_dim):\n",
        "    super(CVAE,self).__init__()\n",
        "    self.latent_dim=latent_dim\n",
        "    self.encoder=tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(28,28,1)),\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3,strides=(2,2),activation='relu'),\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides=(2,2),activation='relu'),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    self.decoder = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
        "            tf.keras.layers.Reshape(target_shape=(7,7,32)),\n",
        "            tf.keras.layers.Conv2DTranspose(filters=64,kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "            tf.keras.layers.Conv2DTranspose(filters=32,kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "            tf.keras.layers.Conv2DTranspose(filters=1,kernel_size=3, strides=1, padding='same'),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "  @tf.function\n",
        "  def sample(self,eps=None):\n",
        "    if eps is None:\n",
        "      eps = tf.random.normal(shape=(100,self.latest_dim))\n",
        "    return self.decode(eps, apply_sigmoid = True)\n",
        "\n",
        "  def encode(self,x):\n",
        "    mean,logvar = tf.split(self.encoder(x),num_or_size_splits=2,axis=1)\n",
        "    return mean,logvar\n",
        "\n",
        "  def reparametrize(self,mean,logvar):\n",
        "    eps = tf.random.normal(shape=mean.shape)\n",
        "    return eps*tf.exp(logvar*.5) + mean\n",
        "\n",
        "  def decode(self,z,apply_sigmoid=False):\n",
        "    logits = self.decode(z)\n",
        "    if apply_sigmoid:\n",
        "      probs = tf.sigmoid(logits)\n",
        "      return probs\n",
        "    return logits"
      ],
      "metadata": {
        "id": "LLi3r0tJddca"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "def log_normal_pdf(sample,mean,logvar,raxis=1):\n",
        "  log2pi = tf.math.log(2*np.pi)\n",
        "  return tf.reduce_sum(\n",
        "      -.5*((sample - mean)**2*tf.exp(-logvar)+log2pi),axis=raxis\n",
        "  )\n",
        "\n",
        "def compute_loss(model,x):\n",
        "  mean,logvar = model.encode(x)\n",
        "  z = model.reparametrize(mean,logvar)\n",
        "  x_logit = model.decode(z)\n",
        "  cross_en = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit,labels=x)\n",
        "  logpx_z = -tf.reduce_sum(cross_en,axis=[1,2,3])\n",
        "  logpz = log_normal_pdf(z,0.,0.)\n",
        "  logqz_x = log_normal_pdf(z,mean,logvar)\n",
        "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "\n",
        "def train_step(model, x, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model,x)\n",
        "  gradients = tape.gradient(loss,model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients,model.trainable_variables))"
      ],
      "metadata": {
        "id": "hy7X8ebNqILH"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}